{"cells":[{"cell_type":"markdown","metadata":{"id":"KHmoqWp0lINb"},"source":["## Training the Neural Network"]},{"cell_type":"markdown","source":["This Tutorial was created by C. Baumhoer and is based on work from https://github.com/mmorphew/unet_remote_sensing & https://github.com/karolzak/keras-unet\n"],"metadata":{"id":"2s6zKk1zl8Qj"}},{"cell_type":"markdown","source":["Again, let's set up the system first.\n"],"metadata":{"id":"yD3ResGdlQrw"}},{"cell_type":"code","source":["#import colab package and mount you accounts associated google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/MET-3"],"metadata":{"id":"ndonhiHXlORS"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tnw7q6NUlINi"},"outputs":[],"source":["%pip install opencv-python matplotlib scikit-image tensorflow keras"]},{"cell_type":"markdown","metadata":{"id":"DLFamf-GlINi"},"source":["----- Set up the Python environment -----"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"THu5PNxnlINj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n","from skimage.transform import resize\n","from skimage.util import random_noise\n","\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n","from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n","from tensorflow.keras.layers import concatenate, add\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","\n","from tensorflow.keras import backend as K"]},{"cell_type":"markdown","metadata":{"id":"XL2qmkrClINk"},"source":["We won't use all of these loss metrics at first, but let's go ahead and define them in case we decide to change our loss function later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkMpF_qKlINl"},"outputs":[],"source":["def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n","\n","def dice_coef(y_true, y_pred, smooth=1):\n","    \"\"\"\n","    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n","         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n","    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n","    \"\"\"\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1-dice_coef(y_true, y_pred)\n","\n","def jaccard_distance_loss(y_true, y_pred, smooth=100):\n","    \"\"\"\n","    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n","            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n","    \n","    The jaccard distance loss is usefull for unbalanced datasets. This has been\n","    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n","    gradient.\n","    \n","    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n","    \n","    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n","    @author: wassname\n","    \"\"\"\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n","    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n","    return (1 - jac) * smooth"]},{"cell_type":"markdown","metadata":{"id":"aVAbvvxJlINm"},"source":["----- read in the data ------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXfgVg9GlINo"},"outputs":[],"source":["data = np.load('./data_train.npy')\n","labels = np.load('./label_train.npy')\n","data_test = np.load('./data_test.npy')\n","labels_test = np.load('./label_test.npy')"]},{"cell_type":"markdown","metadata":{"id":"dJjUJsWNlINp"},"source":["We need to tell Tensorflow the size of our input image. This will depend on how we resized the images during preprocessing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbH_uJFJlINp"},"outputs":[],"source":["nx = 512\n","ny = 512"]},{"cell_type":"markdown","metadata":{"id":"CQCcU-h_lINq"},"source":["To improve learning, let's standardize globally by subtracting the mean and dividing by the standard deviation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i950-ennlINq"},"outputs":[],"source":["# Standardization across all samples (band specific)\n","data_scaled = np.zeros(np.shape(data))\n","data_normalized = np.zeros((np.shape(data)))\n","for i in range(np.shape(data)[-1]):\n","    data_mean = np.mean(data[:,:,:,i])\n","    data_std = np.std(data[:,:,:,i])\n","    data_scaled[:,:,:,i] = (data[:,:,:,i]-data_mean)/data_std\n"]},{"cell_type":"code","source":["# Keep it in the positve range?\n","data_scaled[:,:,:,i] = np.clip((data_scaled[:,:,:,i]+1.0)/2.0,0,1)\n"],"metadata":{"id":"rHxKVULGmU32"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yA0cHaUJlINr"},"outputs":[],"source":["# Standardization across all samples (band specific)\n","data_test_scaled = np.zeros(np.shape(data_test))\n","data_test_normalized = np.zeros((np.shape(data_test)))\n","for i in range(np.shape(data_test)[-1]):\n","    data_test_mean = np.mean(data_test[:,:,:,i])\n","    data_test_std = np.std(data_test[:,:,:,i])\n","    data_test_scaled[:,:,:,i] = (data_test[:,:,:,i]-data_test_mean)/data_test_std"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc-u6fzElINs"},"outputs":[],"source":["x = data_scaled\n","y = labels[:,:,:] # exclude clutter\n","x_test = data_test_scaled\n","y_test = labels_test[:,:,:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gv1eZfhulINs"},"outputs":[],"source":["# Plot a random image to see if everything looks alright\n","plt.imshow(x[15])"]},{"cell_type":"markdown","metadata":{"id":"B2tT_AeslINt"},"source":["Now that we have our data and labels as we want them, we can split our dataset into a portion for training and a portion for validation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NvreIhrmlINt"},"outputs":[],"source":["x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, shuffle=True, random_state=1234)"]},{"cell_type":"markdown","metadata":{"id":"I2-QuGtzlINu"},"source":["We can further augment our training data by introducing data augmentations where we flip the images in various ways, add noise, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gqv_6tMYlINu"},"outputs":[],"source":["# Data augmentation on just the training data\n","## Image Augmentation\n","# Vertical Image\n","Vx = [np.flip(x, axis=1) for x in x_train]\n","Vy = [np.flip(x, axis=1) for x in y_train]\n","\n","# Horizontal Image\n","Hx = [np.flip(x, axis=2) for x in x_train]\n","Hy = [np.flip(x, axis=2) for x in y_train]\n","\n","# Horizontal Vertical Image\n","HVx = [np.flip(x, axis=2) for x in Vx]\n","HVy = [np.flip(x, axis=2) for x in Vy]\n","\n","# Appending the augmented image and mask to the main dataset.\n","x_train = np.append(x_train, Vx, axis=0)\n","y_train = np.append(y_train, Vy, axis=0)\n","\n","x_train = np.append(x_train, Hx, axis=0)\n","y_train = np.append(y_train, Hy, axis=0)\n","\n","x_train = np.append(x_train, HVx, axis=0)\n","y_train = np.append(y_train, HVy, axis=0)\n"]},{"cell_type":"markdown","metadata":{"id":"5FciPP8ZlINu"},"source":["TASK 1: What kind of additional augmentation techniques could we use?"]},{"cell_type":"markdown","metadata":{"id":"dR1ceTGnlINv"},"source":["----- Define the neural network -----"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpxxvB4plINv"},"outputs":[],"source":["# We need some additional layers already pre-defined in Keras\n","from tensorflow.keras.layers import ( \n","        BatchNormalization, Conv2D, Conv2DTranspose,\n","        MaxPooling2D, UpSampling2D, Input,\n","        concatenate\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jsO6qbC3lINw"},"outputs":[],"source":["#https://github.com/karolzak/keras-unet\n","def bn_conv_relu(input, filters, bachnorm_momentum, **conv2d_args):\n","    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n","    x = Conv2D(filters, **conv2d_args)(x)\n","    return x\n","\n","def bn_upconv_relu(input, filters, bachnorm_momentum, **conv2d_trans_args):\n","    x = BatchNormalization(momentum=bachnorm_momentum)(input)\n","    x = Conv2DTranspose(filters, **conv2d_trans_args)(x)\n","    return x\n","\n","def satellite_unet(\n","    input_shape,\n","    num_classes=1,\n","    output_activation='sigmoid',\n","    num_layers=4):\n","\n","    inputs = Input(input_shape)   \n","    \n","    filters = 64\n","    upconv_filters = 96\n","\n","    kernel_size = (3,3)\n","    activation = 'relu'\n","    strides = (1,1)\n","    padding = 'same'\n","    kernel_initializer = 'he_normal'\n","\n","    conv2d_args = {\n","        'kernel_size':kernel_size,\n","        'activation':activation, \n","        'strides':strides,\n","        'padding':padding,\n","        'kernel_initializer':kernel_initializer\n","        }\n","\n","    conv2d_trans_args = {\n","        'kernel_size':kernel_size,\n","        'activation':activation, \n","        'strides':(2,2),\n","        'padding':padding,\n","        'output_padding':(1,1)\n","        }\n","\n","    bachnorm_momentum = 0.01\n","\n","    pool_size = (2,2)\n","    pool_strides = (2,2)\n","    pool_padding = 'valid'\n","\n","    maxpool2d_args = {\n","        'pool_size':pool_size,\n","        'strides':pool_strides,\n","        'padding':pool_padding,\n","        }\n","    \n","    x = Conv2D(filters, **conv2d_args)(inputs)\n","    c1 = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)    \n","    x = bn_conv_relu(c1, filters, bachnorm_momentum, **conv2d_args)\n","    x = MaxPooling2D(**maxpool2d_args)(x)\n","\n","    down_layers = []\n","\n","    for l in range(num_layers):\n","        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","        down_layers.append(x)\n","        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","        x = MaxPooling2D(**maxpool2d_args)(x)\n","\n","    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","    x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n","\n","    for conv in reversed(down_layers):        \n","        x = concatenate([x, conv])  \n","        x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n","        x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","        x = bn_upconv_relu(x, filters, bachnorm_momentum, **conv2d_trans_args)\n","\n","    x = concatenate([x, c1])\n","    x = bn_conv_relu(x, upconv_filters, bachnorm_momentum, **conv2d_args)\n","    x = bn_conv_relu(x, filters, bachnorm_momentum, **conv2d_args)\n","           \n","    outputs = Conv2D(num_classes, kernel_size=(1,1), strides=(1,1), activation=output_activation, padding='valid') (x)       \n","    \n","    model = Model(inputs=[inputs], outputs=[outputs])\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"f9nFZi97lINw"},"source":["Let's create a model object, compile it, and summarize it so we can make sure the layers were built the way we wanted them to be built by Keras. We'll also define our optimizer, Adam, and pick a loss function and tracking metrics."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XxqHp3g9lINw"},"outputs":[],"source":["model = satellite_unet(input_shape=(512, 512, 3), num_classes=2, output_activation='sigmoid', num_layers=3 )\n","model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=[\"categorical_accuracy\", f1])\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"3f0kLvOHlINx"},"source":["TASK 2: Do an online search on the terms optimizer (especially Adam), loss function, activation, batch normalization, unet, callback and early stopping. Write down some notes on every term."]},{"cell_type":"markdown","metadata":{"id":"cxM6DBiMlINx"},"source":["----- "]},{"cell_type":"markdown","metadata":{"id":"9aRCuUGIlINy"},"source":["Callbacks instruct Tensorflow how to behave during training. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bj5-WXKXlINy"},"outputs":[],"source":["#Let's save our model checkpoints relative to epoch and loss\n","checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wiohdAWBlINy"},"outputs":[],"source":["callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=20, verbose=1),\n","    ReduceLROnPlateau(factor=0.1, patience=30, min_lr=0.00001, verbose=1),\n","    ModelCheckpoint(checkpoint_filepath, monitor='val_categorical_accuracy',\n","    mode='max',verbose=1, save_best_only=True, save_weights_only=True)\n","]"]},{"cell_type":"markdown","source":["----- Before Training, Check the system -------"],"metadata":{"id":"iD4sJTHRp0AC"}},{"cell_type":"code","source":["# Storage\n","!free -h"],"metadata":{"id":"EKG7zebzp5c5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#GPU\n","!nvidia-smi -L"],"metadata":{"id":"QTzhXVPXp737"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bFU9NU54lINy"},"source":["Now let's train our model!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xxa60gEClINz"},"outputs":[],"source":["results = model.fit(x_train, y_train, batch_size=4, epochs=20, callbacks=callbacks,\n","                   validation_data=(x_val, y_val))"]},{"cell_type":"markdown","metadata":{"id":"_X5_yim8lIN0"},"source":["TASK 3: Get familiar with the terms epochs and batch size. What impact will we have if you change these parameters?"]},{"cell_type":"markdown","metadata":{"id":"KhnJzcFwlIN0"},"source":["------ Check Accuracy -------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PSI3eqBDlIN0"},"outputs":[],"source":["plt.figure(figsize=(8, 8))\n","plt.title(\"Learning curve\")\n","plt.plot(results.history[\"loss\"], label=\"loss\")\n","plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n","plt.plot(results.history[\"val_categorical_accuracy\"], label=\"val_categorical_accuracy\")\n","plt.plot(results.history[\"categorical_accuracy\"], label=\"categorical_accuracy\")\n","plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"log_loss\")\n","plt.legend();"]},{"cell_type":"markdown","metadata":{"id":"EiWozUb3lIN1"},"source":["-------- Evaluate the trained weights and predict -------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8-nXxT9flIN1"},"outputs":[],"source":["# Load best model\n","#Have a llook at all saved models and take the one with the highest epoch value\n","model.load_weights(\"/content/drive/MyDrive/MET-3/weights.19-0.44.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4BBvktrlIN2"},"outputs":[],"source":["# Evaluate on test set\n","eval = model.evaluate(x_test, y_test)\n","print('Test loss:', eval[0])\n","print('Test accuracy:', eval[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d6slgNulIN2"},"outputs":[],"source":["# Predict on train, val and test\n","preds_train = model.predict(x_train[0:10], verbose=1)\n","preds_val = model.predict(x_val, verbose=1)\n","preds_test = model.predict(x_test, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lXqfocolIN3"},"outputs":[],"source":["# Threshold prediction probabilities\n","preds_train_t = (preds_train > 0.5).astype(np.uint8)\n","preds_val_t = (preds_val > 0.5).astype(np.uint8)\n","preds_test_t = (preds_test > 0.5).astype(np.uint8)"]},{"cell_type":"markdown","metadata":{"id":"C8gmWVHQlIN3"},"source":["--------- Plot Results --------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Rw3bezwlIN3"},"outputs":[],"source":["def plot_sample_all(X, y, preds, binary_preds, ix=None, filename='Sample.png'):\n","    import matplotlib\n","\n","    matplotlib.rc('xtick', labelsize=20) \n","    matplotlib.rc('ytick', labelsize=20) \n","    if ix is None:\n","        ix = random.randint(0, len(X))\n","\n","    has_mask = y[ix].max() > 0\n","\n","    fig, ax = plt.subplots(3, 2, sharex=True, sharey=True, figsize=(20, 10))\n","    r_band = (X[ix,:,:,0]-np.min(X[ix,:,:,0]))/(np.max(X[ix,:,:,0])-np.min(X[ix,:,:,0]))\n","    g_band = (X[ix,:,:,1]-np.min(X[ix,:,:,1]))/(np.max(X[ix,:,:,1])-np.min(X[ix,:,:,1]))\n","    b_band = (X[ix,:,:,2]-np.min(X[ix,:,:,2]))/(np.max(X[ix,:,:,2])-np.min(X[ix,:,:,2]))\n","    RGB = np.stack((r_band, g_band, b_band), axis=-1)\n","\n","    im0 = ax[0,0].imshow(RGB)\n","    #if has_mask:\n","        #ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n","\n","    ax[0,0].set_title('Remote Sensing Image', fontsize=30)\n","    \n","        \n","    im1 = ax[0,1].imshow(X[ix,:,:,0].squeeze(), cmap='gray')\n","\n","    ax[0,1].set_title('Green', fontsize=30)\n","    \n","    im2 = ax[1,0].imshow(X[ix,:,:,2].squeeze(), cmap='gray')\n","\n","    ax[1,0].set_title('NIR', fontsize=30)\n","    \n","    total_mask = np.zeros((512, 512, 3))\n","    for i in range(512):\n","        for j in range(512):\n","            # Ocean\n","            if(y[ix,i,j,0]==1):\n","                total_mask[i,j,0]=1\n","                total_mask[i,j,1]=1\n","                total_mask[i,j,2]=1\n","            # Ice\n","            elif(y[ix,i,j,1]==1):\n","                total_mask[i,j,0]=0\n","                total_mask[i,j,1]=0\n","                total_mask[i,j,2]=1\n","\n","\n","                \n","    im3 = ax[1,1].imshow(total_mask)\n","    ax[1,1].set_title('Image Mask', fontsize=30)\n","    \n","    im4 = ax[2,0].imshow(binary_preds[ix,:,:,0].squeeze(), vmin=0, vmax=1)\n","\n","    ax[2,0].set_title('Ocean (Binary)', fontsize=30)\n","    \n","    im5 = ax[2,1].imshow(binary_preds[ix,:,:,1].squeeze(), vmin=0, vmax=1)\n","\n","    ax[2,1].set_title('Ice (Binary)', fontsize=30)\n","    \n","    plt.xticks(fontsize=20)\n","    plt.yticks(fontsize=20)\n","    \n","    plt.tick_params(axis='both', which='major', labelsize=22)\n","    fig.tight_layout();\n","    plt.savefig(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aDKqzNx3lIN4"},"outputs":[],"source":["# Let's see how a prediction on the training data looks like\n","plot_sample_all(x_train, y_train, preds_train, preds_train_t, ix=9, filename='test.png')"]},{"cell_type":"markdown","metadata":{"id":"-uFOkK0dlIN4"},"source":["This looks really good. What's about our test data?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ag5WEETwlIN5"},"outputs":[],"source":["def plot_sample(X, y, preds, binary_preds, ix=None):\n","    if ix is None:\n","        ix = random.randint(0, len(X))\n","\n","    has_mask = y[ix].max() > 0\n","\n","    fig, ax = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(20, 10))\n","    band = (X[ix,:,:,0]-np.min(X[ix,:,:,0]))/(np.max(X[ix,:,:,0])-np.min(X[ix,:,:,0]))\n","    #print(np.shape(RGB))\n","    im0 = ax[0,0].imshow(band.squeeze(), cmap='gray')\n","    #if has_mask:\n","        #ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n","    fig.colorbar(im0, ax=ax[0,0], fraction=0.046, pad=0.04)\n","    ax[0,0].set_title('Remote Sensing Image')\n","\n","    im1 = ax[0,1].imshow(y[ix,:,:,1].squeeze(), vmin=0, vmax=1)\n","    ax[0,1].set_title('Lable Glacier')\n","    fig.colorbar(im1, ax=ax[0,1],fraction=0.046, pad=0.04)\n","    \n","    im2 = ax[1,0].imshow(preds[ix,:,:,1].squeeze(), vmin=0, vmax=1)\n","    #if has_mask:\n","        #ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n","    fig.colorbar(im2, ax=ax[1,0], fraction=0.046, pad=0.04)\n","    ax[1,0].set_title('Ice Predicted')\n","    \n","    im3 = ax[1,1].imshow(binary_preds[ix,:,:,1].squeeze(), vmin=0, vmax=1)\n","    #if has_mask:\n","        #ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n","    fig.colorbar(im3, ax=ax[1,1], fraction=0.046, pad=0.04)\n","    ax[1,1].set_title('Ice Predicted (Binary)')\n","    fig.tight_layout();"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"TA1VSA1qlIN5"},"outputs":[],"source":["# Check if test data looks all right\n","plot_sample(x_test, y_test, preds_test, preds_test_t, ix=1)"]},{"cell_type":"markdown","metadata":{"id":"fRphhOdglIN5"},"source":["That looks not as good....Well, we only trained on very little data and would need more training data for sophisticated results!"]},{"cell_type":"markdown","metadata":{"id":"8tT1BEIhlIN6"},"source":["-------- Accuracy Metrics -------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmFW6swmlIN6"},"outputs":[],"source":["x_total = np.concatenate((x_train, x_val, x_test), axis=0)\n","y_total = np.concatenate((y_train, y_val, y_test), axis=0)\n","pred_total = np.concatenate((preds_train_t, preds_val_t, preds_test_t), axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i3n18JK8lIN7"},"outputs":[],"source":["def print_roc_metrics(y_real, y_predict):\n","\n","    c_matrix = confusion_matrix(y_real.ravel(), y_predict.ravel())\n","    f1 = f1_score(y_real.ravel(), y_predict.ravel())\n","    recall = recall_score(y_real.ravel(), y_predict.ravel())\n","    precision = precision_score(y_real.ravel(), y_predict.ravel())\n","    print(\"Confusion matrix:\")\n","    print(c_matrix)\n","    print(\"F1 score: {:.4f}\".format(f1))\n","    print(\"Recall score: {:.4f}\".format(recall))\n","    print(\"Precision score: {:.4f}\".format(precision))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-Ahv1aUlIN7"},"outputs":[],"source":["print_roc_metrics(y_val, preds_val_t)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Part2-GlacierFrontDetection-Sentinel-2.ipynb","provenance":[{"file_id":"1u0UtfnfN3ze63A7SWq_GAOHCubv40a2N","timestamp":1655134398505}],"collapsed_sections":[],"private_outputs":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}