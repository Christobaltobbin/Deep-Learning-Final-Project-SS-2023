{"cells":[{"cell_type":"markdown","metadata":{"id":"hfz_gA0qihc6"},"source":["## Data Preparation\n","This Tutorial was created by C. Baumhoer and is based on work from https://github.com/mmorphew/unet_remote_sensing & https://github.com/karolzak/keras-unet"]},{"cell_type":"markdown","source":["----- Access data via Colab ----"],"metadata":{"id":"C0kI2vO2lzfF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFZCplq4ihdB"},"outputs":[],"source":["#import colab package and mount your accounts associated google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["##use % as an meta escape sign to execute cd command\n","# you have to accept the terms and conditions in the pop-up window\n","!mkdir ./drive/My\\ Drive/DL\n","%cd /content/drive/"],"metadata":{"id":"5WZ2hOs5jaWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Nf2QSOvtj6vc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Check whats in your folder\n","#You should see the unziped AP-S2 data\n","%ls"],"metadata":{"id":"aYI2il1rerFK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Change directory into the data folder\n","%cd /content/drive/MyDrive/MET-3"],"metadata":{"id":"8BLfadIFfUhS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["------ Set up the python environment -----"],"metadata":{"id":"tOc2Ok9nmTfV"}},{"cell_type":"code","source":["#Install all packages we need for this tutorial\n","%pip install opencv-python tifffile scikit-image rasterio scipy"],"metadata":{"id":"T0zxH3w5lcZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E4QDUnZQihdC"},"outputs":[],"source":["import cv2\n","import os\n","import tifffile # for reading tiff files. There are other modules that can do this, but tifffile is most stable on Windows\n","import numpy as np # for array handling\n","import matplotlib.pyplot as plt # for QC\n","import glob # to gather up image filepath lists\n","from skimage.transform import resize # we're gonna do some rearranging\n","import rasterio\n","from rasterio.plot import show\n","import scipy # same"]},{"cell_type":"markdown","source":["----- Let's explore the available data -----\n","\n","\n"],"metadata":{"id":"Qk5I4ofNmsvL"}},{"cell_type":"markdown","metadata":{"id":"284XXtwzihdE"},"source":["There are the folders:\n","- scenes\n","- masks\n","- val --> masks\n","\n","\n","The scenes folder includes Sentinel-2 imagery with 3 bands (also called channels in DL-jargon (B3-B4-B8). The mask contains vaule 0 for ocean and value 1 for ice sheet."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnTeXZJgihdE"},"outputs":[],"source":["#Let's have a look at the available files\n","top_train_list = glob.glob('./scenes/*.tif')\n","top_train_list = np.sort(top_train_list)\n","print(top_train_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lv3GDtGkihdG"},"outputs":[],"source":["#Available validation scenes\n","top_test_list = glob.glob('./val/*.tif')\n","top_test_list = np.sort(top_test_list)\n","print(top_test_list)"]},{"cell_type":"markdown","metadata":{"id":"tieQDSMIihdG"},"source":["Lets see how our data looks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_aHJBZ5vihdH"},"outputs":[],"source":["# Plot the first band of a training image\n","src = rasterio.open('./scenes/S2B_MSIL1C_20220128T131859_N0400_R095_T20DNP_20220128T150039-1.tif')\n","img0 = show(src.read(1),transform=src.transform, cmap='gray')"]},{"cell_type":"markdown","metadata":{"id":"bZYspb0yihdI"},"source":["That looks great. We can see the glacier front and the image is already rectangular. All images have the size 512 x 512 pixel, hence no resizing is necessary."]},{"cell_type":"markdown","source":["TASK 1: Print the pixel values of random training scenes. Which range have the pixel values and what do they represent?"],"metadata":{"id":"WPm0HzH6pMYq"}},{"cell_type":"markdown","source":["----- Make our data DL ready -----"],"metadata":{"id":"as9ZRR2wp0dR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tRoNUyHyihdJ"},"outputs":[],"source":["#creating empty arrays to store our data\n","imgResize = 512\n","channels = 3\n","\n","# we create an array that has the shape : sample number, height, width, channel\n","top_train_total = np.zeros((len(top_train_list), imgResize, imgResize, channels)) \n","top_test_total = np.zeros((len(top_test_list), imgResize, imgResize, channels)) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-uU-3rqihdK"},"outputs":[],"source":["for i in range(len(top_train_list)):\n","    img0 = tifffile.imread(top_train_list[i]) # read the image\n","    # resizing the image is not necessary in our case \n","    # as they are all 512 x 512 pixels, but you could use this function if\n","    # you have different sized images\n","    #img_reshaped = resize(img0, (imgResize, imgResize, channels)) # resize it\n","    \n","    # Local normalization & standardization of the image values\n","    img_norm = np.clip((img0 - img0.mean()) / (0.5 * img0.std()), -1, 1)\n","    top_train_total[i] = img_norm # add it to the array"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NgQwgkkeihdL"},"outputs":[],"source":["for i in range(len(top_test_list)):\n","    #img = rasterio.open(top_test_list[i]) # read the image\n","    # nan values to zero\n","    #img0 = np.nan_to_num(img.read(1))\n","    #img_reshaped = resize(img0, (imgResize, imgResize, channels)) # resize it\n","    img0 = tifffile.imread(top_test_list[i]) # read the image\n","    #normalize\n","    img_norm = np.clip((img0 - img0.mean()) / (0.5 * img0.std()), -1, 1)\n","    top_test_total[i] = img_norm # add it to the array"]},{"cell_type":"markdown","metadata":{"id":"GpiQPlrTihdL"},"source":["Great, now that we have both pieces, let's pack it all together."]},{"cell_type":"markdown","source":["TASK 2: Why do we need to scale our image data and what different methods exist? A great resource is: https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/\n"],"metadata":{"id":"lT84EP5HrJO8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6MxVd5_ihdL"},"outputs":[],"source":["# Finally save our data for Part 2\n","np.save('data_train.npy', top_train_total)\n","np.save('data_test.npy', top_test_total)"]},{"cell_type":"markdown","metadata":{"id":"UmXCmmCUihdM"},"source":["----- Processing the labels ------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"luc28cDCihdM"},"outputs":[],"source":["label_train_list = glob.glob('./masks/*.tif')\n","label_train_list = np.sort(label_train_list)\n","print(label_train_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pug8F4jAihdM"},"outputs":[],"source":["label_test_list = glob.glob('./val/masks/*.tif')\n","label_test_list = np.sort(label_test_list)\n","print(label_test_list)"]},{"cell_type":"code","source":["#Lets have a look at our labels\n","img = tifffile.imread(label_train_list[8])\n","plt.imshow(img, cmap='Blues')"],"metadata":{"id":"-wYDfgRPslV6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ld8fCEwcihdO"},"source":["\n","\n","Let's start reshaping our labels."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Na3GKKbHihdO"},"outputs":[],"source":["label_train_total = np.zeros((len(label_train_list), imgResize, imgResize, 1))\n","for i in range(len(label_train_list)):\n","    img = tifffile.imread(label_train_list[i])\n","    #again in our case resizing is not necessary but reshaping\n","    img_reshaped = resize(img, (imgResize, imgResize, 1))\n","    label_train_total[i] = img_reshaped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KR0NvOMmihdO"},"outputs":[],"source":["label_test_total = np.zeros((len(label_test_list), imgResize, imgResize, 1))\n","for i in range(len(label_test_list)):\n","    img = tifffile.imread(label_test_list[i])\n","    img_reshaped = resize(img, (imgResize, imgResize, 1))\n","    label_test_total[i] = img_reshaped"]},{"cell_type":"markdown","source":["TASK 3: What are the label values and dimensions before and after reshaping? And why do we need to one-hot-encode our images?"],"metadata":{"id":"6-tVV-cztM5q"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GiAy787HihdP"},"outputs":[],"source":["onehot_label_train_total = np.zeros((len(label_train_list),imgResize,imgResize,2), dtype=float)\n","for k in range(len(label_train_list)):\n","    for i in range(imgResize):\n","        for j in range(imgResize):\n","            # ocean\n","            if label_train_total[k,i,j,0]==0.:\n","                onehot_label_train_total[k,i,j,0]=1\n","            # ice sheet\n","            elif label_train_total[k,i,j,0]>0:\n","                onehot_label_train_total[k,i,j,1]=1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MbnO_eY6ihdP"},"outputs":[],"source":["onehot_label_test_total = np.zeros((len(label_test_list),imgResize,imgResize,2), dtype=float)\n","for k in range(len(label_test_list)):\n","    for i in range(imgResize):\n","        for j in range(imgResize):\n","            # ocean\n","            if label_test_total[k,i,j,0]==0.:\n","                onehot_label_test_total[k,i,j,0]=1\n","            # ice sheet\n","            elif label_test_total[k,i,j,0]> 0:\n","                onehot_label_test_total[k,i,j,1]=1"]},{"cell_type":"markdown","source":["TASK 4: Check your one-hot-encoded labels regarding dimensions and unique values."],"metadata":{"id":"E6BOhk4yuHmw"}},{"cell_type":"markdown","metadata":{"id":"YyXupSl8ihdP"},"source":["Let's check how our one-hot-encoded labels look like"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvsnXStjihdQ"},"outputs":[],"source":["fig, axes = plt.subplots(1, 2, figsize=(10,10))\n","axes[0].imshow(onehot_label_test_total[2,:,:,0], cmap='gray')\n","axes[1].imshow(onehot_label_test_total[2,:,:,1], cmap='gray')\n","print(np.unique(onehot_label_train_total))"]},{"cell_type":"markdown","metadata":{"id":"8Jmh2mHIihdQ"},"source":["Great, this is looking good. Finnaly, we save our labels for part 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XIx2FG9oihdR"},"outputs":[],"source":["np.save('./label_train.npy', onehot_label_train_total)\n","np.save('./label_test.npy', onehot_label_test_total)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Part1-TrainingDataPreparation.ipynb","provenance":[{"file_id":"1mkeLkkQItJpSvSWcU0uLZXZUHeEwzXVV","timestamp":1655134530522}],"collapsed_sections":[],"private_outputs":true},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}